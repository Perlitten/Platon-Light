{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Platon Light Backtesting Example\n",
    "\n",
    "This notebook demonstrates how to use the Platon Light backtesting module to develop, test, and optimize trading strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "First, let's import the necessary modules and set up our configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# Import Platon Light modules\n",
    "from platon_light.backtesting.data_loader import DataLoader\n",
    "from platon_light.backtesting.backtest_engine import BacktestEngine\n",
    "from platon_light.backtesting.performance_analyzer import PerformanceAnalyzer\n",
    "from platon_light.backtesting.visualization import BacktestVisualizer\n",
    "from platon_light.backtesting.optimization import StrategyOptimizer\n",
    "from platon_light.utils.config_manager import ConfigManager\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Configuration\n",
    "\n",
    "Let's load our backtesting configuration from the `backtest_config.yaml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load configuration\n",
    "config_path = Path.cwd().parent / 'backtest_config.yaml'\n",
    "\n",
    "if not config_path.exists():\n",
    "    # If backtest_config.yaml doesn't exist, use the example config\n",
    "    config_path = Path.cwd().parent / 'backtest_config.example.yaml'\n",
    "    \n",
    "config_manager = ConfigManager(config_path)\n",
    "config = config_manager.get_config()\n",
    "\n",
    "# Display configuration\n",
    "print(\"Backtesting Configuration:\")\n",
    "print(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Historical Data\n",
    "\n",
    "Now, let's load historical market data for our backtesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize data loader\n",
    "data_loader = DataLoader(config)\n",
    "\n",
    "# Define data parameters\n",
    "symbol = \"BTCUSDT\"\n",
    "timeframe = \"1h\"\n",
    "start_date = datetime(2023, 1, 1)\n",
    "end_date = datetime(2023, 3, 31)\n",
    "\n",
    "# Load data\n",
    "data = data_loader.load_data(symbol, timeframe, start_date, end_date)\n",
    "\n",
    "# Display data\n",
    "print(f\"Loaded {len(data)} candles for {symbol} ({timeframe}) from {start_date} to {end_date}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Data\n",
    "\n",
    "Let's visualize the price data to get a better understanding of the market conditions during our backtest period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Convert timestamp to datetime\n",
    "data['datetime'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "\n",
    "# Plot price chart\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data['datetime'], data['close'], label='Close Price')\n",
    "plt.title(f\"{symbol} Price Chart ({timeframe})\", fontsize=14)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Price (USDT)', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Running a Basic Backtest\n",
    "\n",
    "Now, let's run a basic backtest using our default strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize backtest engine\n",
    "backtest_engine = BacktestEngine(config)\n",
    "\n",
    "# Run backtest\n",
    "results = backtest_engine.run(symbol, timeframe, start_date, end_date)\n",
    "\n",
    "# Display basic results\n",
    "print(f\"Total Trades: {len(results['trades'])}\")\n",
    "print(f\"Initial Capital: ${config['backtesting']['initial_capital']}\")\n",
    "print(f\"Final Equity: ${results['equity_curve'][-1]['equity']:.2f}\")\n",
    "print(f\"Return: {(results['equity_curve'][-1]['equity'] / config['backtesting']['initial_capital'] - 1) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyzing Backtest Results\n",
    "\n",
    "Let's analyze the backtest results in more detail using the `PerformanceAnalyzer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize performance analyzer\n",
    "performance_analyzer = PerformanceAnalyzer(config)\n",
    "\n",
    "# Analyze results\n",
    "analysis = performance_analyzer.analyze(results)\n",
    "\n",
    "# Display metrics\n",
    "print(\"Performance Metrics:\")\n",
    "for metric, value in analysis['metrics'].items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{metric}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trade Analysis\n",
    "\n",
    "Let's analyze the trades in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get trade statistics\n",
    "trade_stats = performance_analyzer.get_trade_statistics(results)\n",
    "\n",
    "# Display trade statistics\n",
    "print(\"Trade Statistics:\")\n",
    "for stat, value in trade_stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{stat}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"{stat}: {value}\")\n",
    "\n",
    "# Create a DataFrame from trades\n",
    "trades_df = pd.DataFrame(results['trades'])\n",
    "\n",
    "# Convert timestamps to datetime\n",
    "if not trades_df.empty:\n",
    "    trades_df['entry_time'] = pd.to_datetime(trades_df['entry_time'])\n",
    "    trades_df['exit_time'] = pd.to_datetime(trades_df['exit_time'])\n",
    "    trades_df['duration'] = trades_df['exit_time'] - trades_df['entry_time']\n",
    "    \n",
    "    # Display trades\n",
    "    trades_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizing Backtest Results\n",
    "\n",
    "Let's visualize the backtest results using the `BacktestVisualizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize visualizer\n",
    "visualizer = BacktestVisualizer(config)\n",
    "\n",
    "# Plot equity curve\n",
    "visualizer.plot_equity_curve(results, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot drawdown\n",
    "visualizer.plot_drawdown(results, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot trade distribution\n",
    "visualizer.plot_trade_distribution(results, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot monthly returns\n",
    "visualizer.plot_monthly_returns(results, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Strategy Optimization\n",
    "\n",
    "Now, let's optimize our strategy parameters to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Optimization\n",
    "\n",
    "First, let's use grid search to find the optimal parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize optimizer\n",
    "optimizer = StrategyOptimizer(config)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    \"rsi_period\": [7, 14, 21],\n",
    "    \"rsi_oversold\": [20, 25, 30],\n",
    "    \"rsi_overbought\": [70, 75, 80]\n",
    "}\n",
    "\n",
    "# Run grid search (this may take some time)\n",
    "grid_results = optimizer.grid_search(\n",
    "    param_grid, \n",
    "    symbol, \n",
    "    timeframe, \n",
    "    start_date, \n",
    "    end_date\n",
    ")\n",
    "\n",
    "# Display best parameters\n",
    "print(\"Grid Search Results:\")\n",
    "print(f\"Best Parameters: {grid_results['best_params']}\")\n",
    "print(f\"Best Return: {grid_results['best_metrics']['return_percent']:.2f}%\")\n",
    "print(f\"Best Sharpe Ratio: {grid_results['best_metrics']['sharpe_ratio']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Optimization Results\n",
    "\n",
    "Let's visualize the optimization results to better understand the parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a DataFrame from all results\n",
    "results_df = pd.DataFrame(grid_results['all_results'])\n",
    "\n",
    "# Pivot table for heatmap\n",
    "if 'rsi_period' in param_grid and 'rsi_oversold' in param_grid:\n",
    "    pivot = results_df.pivot_table(\n",
    "        index='rsi_period', \n",
    "        columns='rsi_oversold', \n",
    "        values='return_percent'\n",
    "    )\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(pivot, annot=True, cmap='viridis', fmt='.2f')\n",
    "    plt.title('Return (%) by RSI Period and Oversold Level')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Backtest with Optimized Parameters\n",
    "\n",
    "Now, let's run a backtest with the optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Update config with optimized parameters\n",
    "for param, value in grid_results['best_params'].items():\n",
    "    config['strategy'][param] = value\n",
    "    \n",
    "# Initialize backtest engine with updated config\n",
    "optimized_backtest_engine = BacktestEngine(config)\n",
    "\n",
    "# Run backtest with optimized parameters\n",
    "optimized_results = optimized_backtest_engine.run(symbol, timeframe, start_date, end_date)\n",
    "\n",
    "# Analyze optimized results\n",
    "optimized_analysis = performance_analyzer.analyze(optimized_results)\n",
    "\n",
    "# Display metrics\n",
    "print(\"Optimized Performance Metrics:\")\n",
    "for metric, value in optimized_analysis['metrics'].items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{metric}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparing Strategies\n",
    "\n",
    "Let's compare the original strategy with the optimized strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare strategies\n",
    "comparison = performance_analyzer.compare_strategies(\n",
    "    [results, optimized_results], \n",
    "    [\"Original Strategy\", \"Optimized Strategy\"]\n",
    ")\n",
    "\n",
    "# Display comparison\n",
    "print(\"Strategy Comparison:\")\n",
    "for metric, values in comparison['metrics'].items():\n",
    "    print(f\"{metric}:\")\n",
    "    for i, strategy in enumerate([\"Original\", \"Optimized\"]):\n",
    "        if isinstance(values[i], float):\n",
    "            print(f\"  {strategy}: {values[i]:.2f}\")\n",
    "        else:\n",
    "            print(f\"  {strategy}: {values[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot strategy comparison\n",
    "visualizer.plot_strategy_comparison(\n",
    "    [results, optimized_results], \n",
    "    [\"Original Strategy\", \"Optimized Strategy\"],\n",
    "    save=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Walk-Forward Optimization\n",
    "\n",
    "Let's perform walk-forward optimization to test the robustness of our strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run walk-forward optimization (this may take some time)\n",
    "wfo_results = optimizer.walk_forward_optimization(\n",
    "    param_grid,\n",
    "    symbol,\n",
    "    timeframe,\n",
    "    start_date,\n",
    "    end_date,\n",
    "    window_size=30,  # 30 days in-sample window\n",
    "    step_size=7      # 7 days out-of-sample window\n",
    ")\n",
    "\n",
    "# Display walk-forward optimization results\n",
    "print(\"Walk-Forward Optimization Results:\")\n",
    "for i, window in enumerate(wfo_results['windows']):\n",
    "    print(f\"\\nWindow {i+1}:\")\n",
    "    print(f\"  In-Sample Period: {window['in_sample']['start']} to {window['in_sample']['end']}\")\n",
    "    print(f\"  Out-of-Sample Period: {window['out_sample']['start']} to {window['out_sample']['end']}\")\n",
    "    print(f\"  Best Parameters: {window['in_sample']['best_params']}\")\n",
    "    print(f\"  In-Sample Return: {window['in_sample']['metrics']['return_percent']:.2f}%\")\n",
    "    print(f\"  Out-of-Sample Return: {window['out_sample']['metrics']['return_percent']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Walk-Forward Optimization Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Extract data for visualization\n",
    "windows = []\n",
    "in_sample_returns = []\n",
    "out_sample_returns = []\n",
    "parameter_stability = {}\n",
    "\n",
    "for i, window in enumerate(wfo_results['windows']):\n",
    "    windows.append(i+1)\n",
    "    in_sample_returns.append(window['in_sample']['metrics']['return_percent'])\n",
    "    out_sample_returns.append(window['out_sample']['metrics']['return_percent'])\n",
    "    \n",
    "    # Track parameter stability\n",
    "    for param, value in window['in_sample']['best_params'].items():\n",
    "        if param not in parameter_stability:\n",
    "            parameter_stability[param] = []\n",
    "        parameter_stability[param].append(value)\n",
    "\n",
    "# Plot in-sample vs out-of-sample returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(np.array(windows) - 0.2, in_sample_returns, width=0.4, label='In-Sample Return (%)')\n",
    "plt.bar(np.array(windows) + 0.2, out_sample_returns, width=0.4, label='Out-of-Sample Return (%)')\n",
    "plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "plt.xlabel('Window')\n",
    "plt.ylabel('Return (%)')\n",
    "plt.title('Walk-Forward Optimization: In-Sample vs Out-of-Sample Returns')\n",
    "plt.xticks(windows)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot parameter stability\n",
    "for param, values in parameter_stability.items():\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(windows, values, marker='o', label=param)\n",
    "    plt.xlabel('Window')\n",
    "    plt.ylabel('Parameter Value')\n",
    "    plt.title(f'Parameter Stability: {param}')\n",
    "    plt.xticks(windows)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Multi-Asset Backtesting\n",
    "\n",
    "Let's run backtests on multiple assets to test the strategy's robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define symbols\n",
    "symbols = [\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\"]\n",
    "\n",
    "# Run backtest for each symbol\n",
    "multi_asset_results = {}\n",
    "for sym in symbols:\n",
    "    print(f\"Running backtest for {sym}...\")\n",
    "    results = backtest_engine.run(sym, timeframe, start_date, end_date)\n",
    "    multi_asset_results[sym] = results\n",
    "    \n",
    "    # Display basic results\n",
    "    print(f\"  Total Trades: {len(results['trades'])}\")\n",
    "    print(f\"  Return: {(results['equity_curve'][-1]['equity'] / config['backtesting']['initial_capital'] - 1) * 100:.2f}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Multi-Asset Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze multi-asset results\n",
    "multi_asset_analysis = {}\n",
    "for sym, results in multi_asset_results.items():\n",
    "    multi_asset_analysis[sym] = performance_analyzer.analyze(results)\n",
    "\n",
    "# Create comparison table\n",
    "comparison_data = []\n",
    "for sym, analysis in multi_asset_analysis.items():\n",
    "    metrics = analysis['metrics']\n",
    "    comparison_data.append({\n",
    "        'Symbol': sym,\n",
    "        'Return (%)': metrics['return_percent'],\n",
    "        'Sharpe Ratio': metrics['sharpe_ratio'],\n",
    "        'Max Drawdown (%)': metrics['max_drawdown_percent'],\n",
    "        'Win Rate (%)': metrics['win_rate'],\n",
    "        'Profit Factor': metrics['profit_factor'],\n",
    "        'Total Trades': metrics['total_trades']\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df.set_index('Symbol', inplace=True)\n",
    "\n",
    "# Display comparison\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Multi-Asset Equity Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot equity curves for all assets\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "for sym, results in multi_asset_results.items():\n",
    "    # Create DataFrame from equity curve\n",
    "    equity_df = pd.DataFrame(results['equity_curve'])\n",
    "    equity_df['datetime'] = pd.to_datetime(equity_df['timestamp'], unit='ms')\n",
    "    \n",
    "    # Normalize equity to percentage return\n",
    "    initial_equity = config['backtesting']['initial_capital']\n",
    "    equity_df['return_pct'] = (equity_df['equity'] / initial_equity - 1) * 100\n",
    "    \n",
    "    # Plot equity curve\n",
    "    plt.plot(equity_df['datetime'], equity_df['return_pct'], label=sym)\n",
    "\n",
    "plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "plt.title('Multi-Asset Equity Curves', fontsize=14)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Return (%)', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Creating a Complete Backtest Report\n",
    "\n",
    "Finally, let's create a complete HTML report with all the backtest results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create report for the optimized strategy\n",
    "report_path = visualizer.create_report(optimized_results)\n",
    "print(f\"Report generated at: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use the Platon Light backtesting module to:\n",
    "\n",
    "1. Load historical market data\n",
    "2. Run backtests with different strategies and parameters\n",
    "3. Analyze and visualize backtest results\n",
    "4. Optimize strategy parameters using grid search and walk-forward optimization\n",
    "5. Compare strategy performance across multiple assets\n",
    "6. Generate comprehensive backtest reports\n",
    "\n",
    "This provides a solid foundation for developing and testing trading strategies before deploying them in a live trading environment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
